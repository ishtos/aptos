{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is not available. CPU MODE!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PATH = os.path.join('..', 'input', 'aptos2019-blindness-detection')\n",
    "PATH = os.path.join('..', 'input')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Cuda is available. GPU MODE!')\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print('Cuda is not available. CPU MODE!')\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(PATH, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    return y, label_encoder\n",
    "\n",
    "y, le = prepare_labels(train['diagnosis'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, datatype='train', transform=None, y=None):\n",
    "        \n",
    "        self.df = df\n",
    "        self.datatype = datatype\n",
    "        self.image_files_list = [f'../input/aptos2019-blindness-detection/{self.datatype}_images/{i}.png' for i in self.df['id_code'].values]\n",
    "        \n",
    "        if self.datatype == 'train':\n",
    "            self.labels = y\n",
    "        else:\n",
    "            self.labels = np.zeros((df.shape[0], 5))\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.image_files_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = self.image_files_list[idx]\n",
    "        img = Image.open(img_name)\n",
    "        \n",
    "#       TODO: need to some extra steps to transfer into PIL\n",
    "#         img = cv2.imread(img_name)\n",
    "#         img = self.scale_radius(img, scale)\n",
    "#         img = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), scale / 30), -4, 128)\n",
    "#         img_ = np.zeros(img.shape)\n",
    "#         cv2.circle(img_, (img.shape[1] // 2, img.shape[0] // 2), int(scale * 0.9), (1, 1, 1), -1, 8, 0)\n",
    "#         img = img * img_ + 128 * (1 - img_)\n",
    "\n",
    "        image = self.transform(img)\n",
    "        \n",
    "        img_name_short = img_name.split('.')[0]\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        if self.datatype == 'test':\n",
    "            return image, label, img_name\n",
    "        else:\n",
    "            return image, label\n",
    "        \n",
    "    def scale_radius(img, scale):\n",
    "        \n",
    "        x = img[img.shape[0] // 2, :, :].sum(axis = 1)\n",
    "        r = (x > x.mean() / 10).sum() / 2\n",
    "        s = scale * 1.0 / r\n",
    "        \n",
    "        return cv2.resize(img, (0, 0), fx = s, fy = s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train_list = []\n",
    "transforms_test_list = []\n",
    "\n",
    "if config['transforms_library'] == 'pytorch':\n",
    "    if config['resize']:\n",
    "        transforms_train_list.append(transforms.Resize(size=(config['image_size'], config['image_size'])))\n",
    "    if config['randomHorizontalFlip']:\n",
    "        transforms_train_list.append(transforms.RandomHorizontalFlip())\n",
    "    if config['randomRotation']:\n",
    "        transforms_train_list.append(transforms.RandomRotation())\n",
    "    if config['toTrnsor']:\n",
    "        transforms_train_list.append(transforms.ToTensor())\n",
    "    if config['normalize']:\n",
    "        transforms_train_list.append(transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "    train_transforms = transforms.Compose(transforms_train_list)\n",
    "else:\n",
    "    if config['resize']:\n",
    "        transdorms_train_list.append(A.Resize(size=(config['image_size'], config['image_size'])))\n",
    "    if config['horizontalFlip']:\n",
    "        transforms_train_list.append(A.HorizontalFlip())\n",
    "    if config['rotate']:\n",
    "        transforms_train_list.append(A.Rotate())\n",
    "    if config;['randomBrightness']:\n",
    "        transforms_train_list.append(A.RandomBrightness())\n",
    "    if config['randomContrast']:\n",
    "        transforms_train_list.append(A.RandomContrast())\n",
    "    if config['randomBrightnessContrast']:\n",
    "        transforms_train_list.append(A.RandomBrightnessContrast())\n",
    "    if config['hueSaturationValue']:\n",
    "        transforms_train_list.append(A.HueSaturationValue())\n",
    "    if config['toTensor']:\n",
    "        transforms_train_list.append(A.torch.ToTensor())\n",
    "    if config['normalize']:\n",
    "        transforms_train_list.append(A.normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "    train_transforms = albumentations.Compose(transforms_train_list)\n",
    "\n",
    "    \n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=360),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DRDataset(df=train, datatype='train', transform=train_transforms, y=y)\n",
    "test_dataset = DRDataset(df=test, datatype='test', transform=test_transforms)\n",
    "\n",
    "tr, val = train_test_split(train.diagnosis, stratify=train.diagnosis, test_size=0.1)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(list(tr.index))\n",
    "valid_sampler = SubsetRandomSampler(list(val.index))\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 0\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRDetect(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(DRDetect, self).__init__()\n",
    "        self.model = torchvision.models.resnet101()\n",
    "        self.model.load_state_dict(torch.load(os.path.join('..', 'input', 'fastai-pretrained-models', 'resnet101-5d3b4d8f.pth')))\n",
    "        slef.model.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(in_features=2048, out_features=2048, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2048, out_features=1, bias=True),\n",
    "        )\n",
    "    \n",
    "#     def make_graph():\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DRDetect().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.003\n",
    "momentum = 0.99\n",
    "factor = 0.5\n",
    "patience = 2\n",
    "\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS & OPTIMIZER & SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=factor, patience=patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN & VALID & TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        if device == 'cuda':\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_loss += loss.data\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, criterion, optimizer, valid_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0\n",
    "    for _, (data, target) in enumerate(valid_loader):\n",
    "        if device == 'cuda':\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        running_loss += loss.data\n",
    "                \n",
    "    return running_loss / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device, sub):\n",
    "    model.eval()\n",
    "    \n",
    "    for (data, _, name) in test_loader:\n",
    "        if device == 'cuda':\n",
    "            data = data.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        output = output.cpu().detach().numpy()\n",
    "        \n",
    "        for i, (e, n) in enumerate(list(zip(output, name))):\n",
    "            sub.loc[sub['id_code'] == n.split('/')[-1].split('.')[0], 'diagnosis'] = le.inverse_transform([np.argmax(e)])\n",
    "   \n",
    "    return sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val = 1000000000\n",
    "\n",
    "for epoch in tqdm(n_epochs):\n",
    "    train_loss = train(model, criterion, optimizer, train_loader, device)\n",
    "    val_loss = valid(model, criterion, optimizer, valid_loader, device)\n",
    "    \n",
    "    print('epoch {:d}, loss: {:.4f} val_loss: {:.4f}'.format(epoch, loss, val_loss))\n",
    "    \n",
    "    if val_loss < best_val:\n",
    "        print('val_loss improved from {:.5f} to {:.5f}!'.format(best_val, val_loss))\n",
    "        best_val = val_loss            \n",
    "        model_file = 'best.pth'.format(epoch, val_loss)\n",
    "        torch.save(model.state_dict(), os.path.join(log_dir, model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))\n",
    "sub = test(model, test_loader, device, sub)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from oauth2client import client\n",
    "from oauth2client.file import Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('../input/credential.json', scope)\n",
    "gc = gspread.authorize(credentials)\n",
    "wks = gc.open('APTOS').sheet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Cell R1C1 'Hello World!'>\n"
     ]
    }
   ],
   "source": [
    "wks.update_acell('A1', 'Hello World!')\n",
    "print(wks.acell('A1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
